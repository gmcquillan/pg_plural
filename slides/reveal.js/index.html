<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js - The HTML Presentation Framework</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/pg_plural.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>Data of Future Past</h1>
					<h3>Postgres as Distributed Online Processing Analytics Engine</h3>
					<img width="250" height="300" data-src="images/shard_elephant.png" alt="shard elephant" />
					<p>
						by <a href="http://github.com/gmcquillan">Gavin McQuillan</a> / <a href="http://twitter.com/gmcquillan">@gmcquillan</a>
					</p>
				</section>

				<section>
					<h2>Setting</h2>
					<p>Data Engineering at Urban Airship, a mobile messaging company:</p>
					<ul>
						<li>Counting lots of things as fast as possible</li>
						<li>HBase to the rescue</li>
						<li>Home grown dimensional storage called <a href="https://github.com/urbanairship/datacube">datacube</a></li>
					</ul>
				</section>

				<section>
					<h3>Postgres as Distributed Online Processing Analytics Engine</h3>
					<ol>
						<li>Problem Statement</li>
                                                <li>Distributed Postgres</li>
                                                <li>Probabalistic Datastructures</li>
						<li>Benchmarking Solutions, Unloaded/Loaded.</li>
					</ol>
				</section>

				<section>
					<img style="float:left" width="250" height="300" data-src="images/shard_elephant.png" alt="shard elephant" />
					<h2>The Problem</h2>
					<ul>
						<li>Data consistency</li>
						<li>New dimensions multiply writes</li>
						<li>Double counting</li>
						<li>Changing schema is hard</li>
						<li>Consistent backups?</li>
					</ul>
				</section>

				<section>
					<h2>Exploring Solutions</h2>
					<p>Postgres is pretty nice to work with.</p>
					<p>Makes adhoc analytics simple.</p>
					<p>Well known replication and backup story</p>
				</section>
 
				<section>
					<h2>Problems with Postgres</h2>
					<p>Not particularly good at scaling writes horizontally</p>
					<p>Operationally complex</p>
				</section>

				<section>
					<h2>PLProxy</h2>
					<ul>
						<li>Simple API</li>
						<li>Battle tested</li>
						<li>Flexible</li>
						<li>Easy upgrade paths, no lock-in</li>
					</ul>
				</section>

				<section>
					<h2>Approach</h2>
					<p>Two phase commit</p>
					<p>Commutative, Idempotent data</p>
				</section>

				<section>
					<h2>Idempotent Writes with HyperLogLog</h2>
					<p>Postgres-hll extension</p>
					<p>Commutative, idempotent</p>
					<p>Fast, approximate, cardinality</p>
				</section>

				<section>
					<h2>Briefly, how Hyperloglog works</h2>
					<img data-src="images/hll_diagram.png" alt="hll diagram" />
				</section>

				<section>
					<h2>PLProxy: Setting up Foreign Data Wrappers in SQL.</h2>
				</section>

				<section>
					<h2>Cluster Config</h2>
					<p>Partition defs, cluster version, connection config elided</p>
					<p>Partition mapping is as follows:</p>
				</section>

				<section>
					<h2>Partition Mapping</h2>
					<pre><code data-trim contenteditable>
CREATE FOREIGN DATA WRAPPER plproxy;

CREATE SERVER testcounts FOREIGN DATA WRAPPER plproxy
OPTIONS (connection_lifetime '1800',
         p0 'dbname=part00 host=10.130.1.38',
         p1 'dbname=part01 host=10.130.1.39' );

-- This mapping is accessible to all local users
CREATE USER MAPPING FOR PUBLIC SERVER testcounts;
					</code></pre>
				</section>

				<section>
					<h2>Proxy Functions</h2>
					<pre><code data-trim contenteditable>
CREATE OR REPLACE FUNCTION upsert_count(
	in_id text, in_date date, in_hour smallint,
	in_event_id text, in_category text
) RETURNS TABLE (updates int)
	LANGUAGE plproxy
	AS $$
	CLUSTER 'testcounts';
	RUN ON hashtext(in_event_id);
$$;
					</code></pre>
				</section>

				<section>
					<h2>PL Syntax Explained</h2>
					<img src="images/pl_functions.png" />
				</section>


				<section>

					<img width="250" height="300" data-src="images/shard_elephant.png" alt="shard elephant" />
					<h1>Experimental Design</h1>
				</section>

 				<section>
					<h2>Physical Layout</h2>
					<p>Three Dell R610s with:</p>
					<ul>
						<li>2 8-core Xeon CPUs</li>
						<li>6 SSDs in a RAID 10 configuration (~300GB usable)</li>
						<li>write-back cache enabled on the I/O controller</li>
						<li>48GB of ECC RAM.</li>
						<li>Bonded Ethernet interfaces</li>
					</ul>
				</section>

				<section>
					<h2>Simple Topology</h2>
					<img src="images/simple_topology.png" />
				</section>

				<section>
					<h1>Setting up the Shards</h1>
				</section>

				<section>
					<h2>Example table</h2>
					<pre><code data-trim contenteditable>
CREATE TABLE test_counts
(
	id CHAR(22),
	date DATE,
	hour SMALLINT,
	event_ids hll,
	category TEXT
);
					</code></pre>
				</section>

				<section>
					<h2>Single Insert/Update</h2>
					<pre><code data-trim contenteditable>
CREATE OR REPLACE FUNCTION upsert_test_count(...) RETURNS int
BEGIN
    UPDATE test_counts set event_ids=hll_add(
			event_ids, hll_hash_text(in_event_id))
        WHERE ... 
    IF FOUND THEN RETURN 0; END IF;
    BEGIN
        INSERT INTO test_counts(event_ids, ...)
          VALUES (hll_empty(), ...);
        Update test_counts SET event_ids=hll_add(
			event_ids, hll_hash_text(in_event_id))
        WHERE ...
    END;
    RETURN 1;
END;
					</code></pre>

                                        <p>Argument types other than hll field elided</p>
				</section>

				<section>
					<h2>Single Write</h2>
					<pre><code data-trim contenteditable>
select upsert_test_count(
	'some-identifier-string'::text,
	'2015-05-16'::date,
	'22'::smallint,
	'cabef32d-bc21-4a34-993d-3e7d606df9c6'::text,
	'Catagory1'::text
);
					</code></pre>
				</section>



				<section>
					<h2>Tuning</h2>
                                        <ul>
					<li>Optimum index configuration (3/4 dimensions indexed)</li>
					<li>The fillfactor tells Postgres to pre-allocate 90% of the index space empty, copy data less.</li>
                                        <li>Standard best practices for workMem, and other memory settings</li>
                                        </ul>
				</section>


				<section>
					<h2>Still too slow</h2>
					<p>~2,000 events/sec</p>
					<p>A transaction per tuple just won't work long-term</p>
				</section>

				<section>
					<h2>Batching</h2>

					<pre><code data-trim contenteditable>
CREATE OR REPLACE FUNCTION upsert_test_count(
    in_ids text[], in_dates date[], in_hours smallint[],
	in_event_ids text[], in_cats text[]
) RETURNS TABLE (update int)
BEGIN

RETURN QUERY SELECT upsert_push_hll(
	c.in_ids, c.in_date, c.in_hour, c.in_event_id, c.in_cats
) FROM unnest(
	in_ids, in_dates, in_hours, in_event_ids, in_cats
) as c (in_id, in_date, in_hour, in_event_id, in_cats);
END;
$$;
					</code></pre>
				</section>

				<section>
					<h2>Batch Write Query</h2>
					<pre><code data-trim contenteditable>
select upsert_test_count(
	'{aaaaaaaaaaaaaaaaaaaaaa, ..., ...}'::text[],
	'{2015-05-15,2015-05-16,2015-05-16}'::date[],
	'{20,21,23}'::smallint[],
	'{cabef32d-bc21-4a34-993d-3e7d606df9b1, ..., ...}'::text[],
	'{Category1,Catagory2,Category1}'::text[]
);
					</code></pre>
				</section>

				<section>
					<h2>Anatomy of a PLProxy Transaction</h2>
					<img src="images/transaction_good.png" />
				</section>

				<section>
					<h2>When Things Go Wrong</h2>
					<img src="images/transaction_bad.png" />
				</section>

				<section>
					<h2>Deadlock detected!</h2>
					<img src="images/deadlock.png" />
				</section>

				<section>
					<h2>Deadlock Solutions</h2>
					<ul>
						<li>Sort tuples before submitting them</li>
						<li>Single writer pattern</li>
					</ul>
					<p>Our functions make sorting difficult, so single writer</p>
				</section>

				<section>
					<h2>Simple Topology</h2>
					<p>Peaks out with tuning, indexes, and batching at <strong>11k events/sec</strong></p>
					<p>Next step is to increase parallelism</p>

				</section>

				<section>
					<img width="250" height="300" data-src="images/shard_elephant.png" alt="shard elephant" />
					<h1>Benchmark Results</h2>
				</section>

				<section>
					<h2>Simple Topology Throughput (200K)</h2>
					<img src="images/throughput_simple.png" />
				</section>

				<section>
					<h2>Advanced Topology</h2>
					<img src="images/advanced_topology.png" />
				</section>

				<section>
					<h2>Advanced Topology Throughput (2MM)</h2>
					<img src="images/throughput_advanced.png" />
				</section>

				<section>
					<h2>Direct Comparison (2MM)</h2>
					<img src="images/throughput_advanced_vs_simple.png" />
				</section>

				<section>
					<img width="250" height="300" data-src="images/shard_elephant.png" alt="shard elephant" />
					<h2>Benchmarks on a Loaded Cluster</h2>
				</section>

				<section>
					<h2>Types of Load</h2>
					<ol>
						<li>Data load: number of rows, size on disk</li>
						<li>Concurrent requests</li>
					</ol>
				</section>

				<section>
					<h2>Setting up a loaded system</h2>

                                        <ol>
                                            <li>60G of test data</li>
                                            <li>20G of indexes</li>
                                            <li>Added 20G more data, and 6G more indexes</li>
                                        </ol>


				</section>

				<section>

					<h2>Setting up concurrent requests</h2>

                                        <ul>
                                            <li>Pre-generate insert query batches into .sql files</li>
                                            <li>Run 10 concurrently in a screen session</li>
                                            <li>Not 100% representative of real-world behavior</li>
                                        </ul>

				</section>

				<section>
					<h2>Loaded Results</h2>
					<img src="images/throughput_advanced_load.png" />
				</section>

				<section>
					<h2>Read Query (AdHoc)</h2>
					<pre><code data-trim contenteditable>
SELECT id, date, hour, hll_cardinality(event_ids)
FROM dynamic_query(  
	'SELECT * from test_counts 
	WHERE date >= (now() - interval ''7 days'')  
	   AND id = ''M2E0MDdlNzYtY2Y4NC00Nz'''  
) AS (  
    id char(22),date date,hour smallint,event_ids hll, cat text)   
ORDER BY   
    date desc,   
    hour desc   
LIMIT 10;  

					</code></pre>
				</section>

				<section>
					<h2>Read Query Results</h2>
					<pre><code data-trim contenteditable>
id        	    |    date    | hour | hll_cardinality   
------------------------+------------+------+-----------------  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |   18 |               6  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |   13 |               6  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |   13 |               6  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |    6 |               6  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |   21 |               5  
					</code></pre>
				</section>

				<section>
					<h2>Wrap Up: Postgres for Distributed OLAP</h2>
					<ul>
						<li>Postgres can scale horizontally.</li>
						<li>Write throughput ~= Hbase system.</li>
						<li>New features are a few lines of SQL</li>
						<li>We <strong>retain</strong> queryability and DDLs</li>
						<li>Operational concerns only get worse :(</li>
					</ul>
				</section>

				<section>
					<img width="250" height="300" data-src="images/shard_elephant.png" alt="shard elephant" />
					<h1>Remaining Work</h1>
				</section>

				<section>
					<h2>Future Features</h2>
					<ul>
						<li>Cross table joins</li>
						<li>Automated failovers(shards)</li>
						<li>Automated, efficient backups</li>
						<li>Tools to help migrate data, add partitions</li>
						<li>Integrating PGBouncer</li>
					<ul>
				</section>

				<section>
					<h2>Work is Ongoing</h2>
					<p>Ansible automation for setting up a test cluster</p>
					<p><a href="https://github.com/gmcquillan/pg_plural">github.com/gmcquillan/pg_plural</a></p>
				</section>

				<section>
					<img width="250" height="300" data-src="images/shard_elephant.png" alt="shard elephant" />
					<h1>Thank You</h1>
				</section>

				<section>
					<h2>References</h2>
					<ul>
						<li><a href="http://plproxy.projects.pgfoundry.org/doc/syntax.html">PLProxy Syntax Reference</a></li>
						<li><a href="http://plproxy.projects.pgfoundry.org/doc/faq.html">PLProxy FAQ</a></li>
						<li><a href="https://www.youtube.com/watch?v=5ZjhNTM8XU8">Martin Kleppmann on Transactions [VIDEO]</a></li>
						<li><a href="http://www.depesz.com/2011/12/02/the-secret-ingredient-in-the-webscale-sauce/">depesz.com</a></li>
						<li><a href="http://en.pgconf.ru/static/presentations/2015/urbanski.pdf">Urbanski Presentation at pgconf.ru [PDF]</a></li>
						<li><a href="http://www.postgresql.org/docs/current/interactive/explicit-locking.html#LOCKING-DEADLOCKS">Deadlocks in Postgresql</a></li>
						<li><a href="http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf">HyperLogLog: the analysis of near-optimal cardinality estimation algorithm - Flajolet [PDF]</a></li>
					</ul>

				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: false,
				progress: true,
				history: true,
				center: true,
				slideNumber: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});
			Reveal.configure({ slideNumber: 'c / t' });

		</script>

	</body>
</html>
