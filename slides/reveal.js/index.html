<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js - The HTML Presentation Framework</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/pg_plural.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>Data of Future Past</h1>
					<h3>Postgres as Distributed Online Processing Analytics Engine</h3>
					<img width="250" height="300" data-src="images/shard_elephant.png" alt="shard elephant" />
					<p>
						<small>by <a href="http://github.com/gmcquillan">Gavin McQuillan</a> / <a href="http://twitter.com/gmcquillan">@gmcquillan</a></small>
					</p>
				</section>

				<section>
					<h2>Setting</h2>
					<p>Data Engineering at Urban Airship, a mobile messaging company:</p>
					<ul>
						<li>Counting lots of things as fast as possible</li>
						<li>HBase to the rescue</li>
						<li>Home grown dimensional storage called <a href="https://github.com/urbanairship/datacube">datacube</a></li>
					</ul>
				</section>

				<section>
					<h2>The Problem</h2>
					<ul>
						<li>Data consistency</li>
						<li>New dimensions multiply writes</li>
						<li>Double counting</li>
						<li>Changing schema is hard</li>
						<li>Consistent backups?</li>
					</ul>
				</section>

				<section>
					<h2>Exploring Solutions</h2>
					<p>Postgres is pretty nice to work with.</p>
					<p>Makes adhoc analytics simple.</p>
					<p>Well known replication and backup story</p>
				</section>
 
				<section>
					<h2>Problems with Postgres</h2>
					<p>Not particularly good at scaling writes</p>
					<p>Operationally complex</p>
				</section>

				<section>
					<h2>I chose PLProxy</h2>
					<ul>
						<li>Simple API</li>
						<li>Battle tested</li>
						<li>Flexible</li>
					</ul>

					<p>Maybe better options exist?</p>
				</section>


				<section>
					<h2>Approach</h2>
					<p>Two phase commit</p>
					<p>Commutative, Idempotent data</p>
				</section>

				<section>
					<h2>HyperLogLog</h2>
					<p>Postgres-hll extension</p>
					<p>Commutative, idempotent</p>
					<p>Fast, approximate, cardinality</p>
				</section>

				<section>
					<h1>Experimental Design</h1>
				</section>

 				<section>
					<h2>Physical Layout</h2>
					<p>Three Dell R610s with:</p>
					<ul>
						<li>2 8-core Xeon CPUs</li>
						<li>6 SSDs in a RAID 10 configuration (~300GB usable)</li>
						<li>write-back cache enabled on the I/O controller</li>
						<li>48GB of ECC RAM.</li>
						<li>Bonded Ethernet interfaces</li>
					</ul>
				</section>

				<section>
					<h2>Simple Topology</h2>
					<img src="images/simple_topology.png" />
				</section>

				<section>
					<h2>Example table</h2>
					<pre><code data-trim contenteditable>
CREATE TABLE test_counts
(
	id CHAR(22),
	date DATE,
	hour SMALLINT,
	event_ids hll,
	category TEXT
);
					</code></pre>
				</section>

				<section>
					<h2>Single Insert/Update</h2>
					<pre><code data-trim contenteditable>
CREATE OR REPLACE FUNCTION upsert_test_count(...) RETURNS int
BEGIN
    UPDATE test_counts set event_ids=hll_add(
			event_ids, hll_hash_text(in_event_id))
        WHERE ... 
    IF FOUND THEN RETURN 0; END IF;
    BEGIN
        INSERT INTO test_counts(event_ids, ...)
          VALUES (hll_empty(), ...);
        Update test_counts SET event_ids=hll_add(
			event_ids, hll_hash_text(in_event_id))
        WHERE ...
    END;
    RETURN 1;
END;
					</code></pre>
				</section>

				<section>
					<h2>Single Write</h2>
					<pre><code data-trim contenteditable>
select upsert_test_count(
	'some-identifier-string'::text,
	'2015-05-16'::date,
	'22'::smallint,
	'cabef32d-bc21-4a34-993d-3e7d606df9c6'::text,
	'Catagory1'::text
);
					</code></pre>
				</section>

				<section>
					<h2>Postgres Tuning Parameters</h2>

					<table>
						<thead>
							<tr>
								<th>Config Parameter</th>
								<th>My Setting</th>
								<th>Notes</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>shared_buffers</td>
								<td>10GB</td>
								<td>25% of memory</td>
							</tr>
							<tr>
								<td>effective_cache_size</td>
								<td>30GB</td>
								<td>75% of memory</td>
							</tr>
							<tr>
								<td>work_mem</td>
								<td>50MB</td>
								<td>sorting, etc. it's also per-session</td>
							</tr>
							<tr>
								<td>random_page_cost</td>
								<td>2.0</td>
								<td>default is 4.0; SSDs here.</td>
							</tr>
								<td>checkpoint_segments</td>
								<td>256</td>
								<td>default 32; number WAL segments to buffer</td>
						</tbody>
					</table>

				</section>

				<section>
					<h2>Indexes</h2>

					<p>Optimum index configuration (3/4 dimensions indexed):</p>

					<pre><code data-trim contenteditable>
create index on test_counts (id, date, hour) with(fillfactor=10);
				</code></pre>

					<p>The fillfactor tells Postgres to pre-allocate 90% of the index space empty, copy data less.</p>
				</section>

				<section>
					<h2>Still too slow</h2>
					<p>~2,000 events/sec</p>
					<p>A transaction per tuple just won't work long-term</p>
				</section>

				<section>
					<h2>Batching</h2>

					<pre><code data-trim contenteditable>
CREATE OR REPLACE FUNCTION upsert_test_count(
    in_ids text[], in_dates date[], in_hours smallint[],
	in_event_ids text[], in_cats text[]
) RETURNS TABLE (update int)
BEGIN

RETURN QUERY SELECT upsert_push_hll(
	c.in_ids, c.in_date, c.in_hour, c.in_event_id, c.in_cats
) FROM unnest(
	in_ids, in_dates, in_hours, in_event_ids, in_cats
) as c (in_id, in_date, in_hour, in_event_id, in_cats);
END;
$$;
					</code></pre>
				</section>

				<section>
					<h2>Batch Write Query</h2>
					<pre><code data-trim contenteditable>
select upsert_test_count(
	'{aaaaaaaaaaaaaaaaaaaaaa, ..., ...}'::text[],
	'{2015-05-15,2015-05-16,2015-05-16}'::date[],
	'{20,21,23}'::smallint[],
	'{cabef32d-bc21-4a34-993d-3e7d606df9b1, ..., ...}'::text[],
	'{Category1,Catagory2,Category1}'::text[]
);
					</code></pre>
				</section>

				<section>
					<h2>Anatomy of a PLProxy Transaction</h2>
					<img src="images/transaction_good.png" />
				</section>

				<section>
					<h2>When Things Go Wrong</h2>
					<img src="images/transaction_bad.png" />
				</section>

				<section>
					<h2>Deadlock detected!</h2>
					<img src="images/deadlock.png" />
				</section>

				<section>
					<h2>Deadlock Solutions</h2>
					<ul>
						<li>Sort tuples before submitting them*</li>
						<li>Single writer pattern</li>
					</ul>
					<p>* Only decreases odds of deadlock</p>
				</section>

				<section>
					<h2>Simple Topology</h2>
					<p>Peaks out with tuning, indexes, and batching at <strong>11k events/sec</strong></p>
					<p>Next step is to increase parallelism</p>

				</section>

				<section>
					<h2>Advanced Topology</h2>
					<img src="images/advanced_topology.png" />
				</section>


				<section>
					<h1>Experimental Results</h2>
				</section>

				<section>
					<h2>Simple Topology Throughput (200K)</h2>
					<img src="images/throughput_simple.png" />
				</section>

				<section>
					<h2>Advanced Topology Throughput (2MM)</h2>
					<img src="images/throughput_advanced.png" />
				</section>

				<section>
					<h2>Direct Comparison (2MM)</h2>
					<img src="images/throughput_advanced_vs_simple.png" />
				</section>

				<section>
					<h1>Let's See Results on a Loaded Cluster!</h1>
				</section>

				<section>
					<h2>Types of Load</h2>
					<ol>
						<li>Data load: number of rows, size on disk</li>
						<li>Concurrent requests</li>
					</ol>
				</section>

				<section>
					<h2>Setting up a loaded system</h2>

					<table>
						<thead>
							<tr>
								<th>Cluster State</th>
								<th>Cluster Size (MB)</th>
								<th>Index Size(MB)</th>
								<th>Number of Rows</th>
								<th>Number of IDs</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Before</td>
								<td>63,864</td>
								<td>21,824</td>
								<td>333,757,839</td>
								<td>307,520</td>
							</tr>
							<tr>
								<td>After</td>
								<td>80,096</td>
								<td>27,088</td>
								<td>412,900,728</td>
								<td>357,520</td>
							</tr>

						</tbody>
					</table>
				</section>

				<section>

					<h2>Setting up concurrent requests</h2>

					<p>Pre-generate insert query batches into .sql files</p>
					<p>Run 10 concurrently in a screen session</p>
					<p>Not 100% representative of real-world behavior</p>

				</section>

				<section>
					<h2>Loaded Results</h2>
					<img src="images/throughput_advanced_load.png" />
				</section>

				<section>
					<h2>Read Query</h2>
					<pre><code data-trim contenteditable>
SELECT id, date, hour, hll_cardinality(event_ids)
FROM dynamic_query(  
	'SELECT * from test_counts 
	WHERE date >= (now() - interval ''7 days'')  
	   AND id = ''M2E0MDdlNzYtY2Y4NC00Nz'''  
) AS (  
    id char(22),date date,hour smallint,event_ids hll, cat text)   
ORDER BY   
    date desc,   
    hour desc   
LIMIT 10;  

					</code></pre>
				</section>

				<section>
					<h2>Read Query</h2>
					<pre><code data-trim contenteditable>

         id        	    |    date    | hour | hll_cardinality   
------------------------+------------+------+-----------------  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |   18 |               6  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |   13 |               6  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |   13 |               6  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |    6 |               6  
 M2E0MDdlNzYtY2Y4NC00Nz | 2015-06-10 |   21 |               5  
					</code></pre>
				</section>

				<section>
					<h2>Read Latency</h2>
					<p>Generally 10's to 100's of ms</p>
		
				</section>

				<section>
					<h2>Read Variability</h2>
					<p>Total numbers of test data for a given id are highly variable.</p>
				</section>

				<section>
					<h2>Inspect Variability</h2>
					<pre><code data-trim contenteditable>
SELECT id, sum(count)
FROM dynamic_query(
	'SELECT id, count(push_ids) FROM test_counts GROUP BY id'
) AS (id char(22), count bigint)
GROUP BY id ORDER by sum DESC LIMIT 20; 	

       id 				|  sum    
------------------------+-------  
 NTdlYWE3N2QtNDg0My00ND | 15953  
 NjU5MDVjMWYtNDI1OC00NG | 15949
					</code></pre>
				</section>

				<section>
					<h2>Wrap Up: Postgres for Distributed OLAP</h2>
					<ul>
						<li>Postgres can scale horizontally.</li>
						<li>Write throughput ~= Hbase system.</li>
						<li>New features are a few lines of SQL</li>
						<li>We <strong>retain</strong> queryability and DDLs</li>
						<li>Operational concerns only get worse :(</li>
					</ul>
				</section>

				<section>
					<h1>Remaining Work</h1>
				</section>

				<section>
					<h2>Future Features</h2>
					<ul>
						<li>Cross table joins</li>
						<li>Automated failovers(shards)</li>
						<li>Automated, efficient backups</li>
						<li>Tools to help migrate data, add partitions</li>
						<li>Integrating PGBouncer</li>
					<ul>
				</section>

				<section>
					<h2>Work is Ongoing</h2>
					<p>Ansible automation for setting up a test cluster</p>
					<p><a href="https://github.com/gmcquillan/pg_plural">github.com/gmcquillan/pg_plural</a></p>
				</section>

				<section>
					<h1>Thank You</h1>
				</section>

				<section>
					<h2>References</h2>
					<ul>
						<li><a href="http://plproxy.projects.pgfoundry.org/doc/syntax.html">PLProxy Syntax Reference</a></li>
						<li><a href="http://plproxy.projects.pgfoundry.org/doc/faq.html">PLProxy FAQ</a></li>
						<li><a href="https://www.youtube.com/watch?v=5ZjhNTM8XU8">Martin Kleppmann on Transactions [VIDEO]</a></li>
						<li><a href="http://www.depesz.com/2011/12/02/the-secret-ingredient-in-the-webscale-sauce/">depesz.com</a></li>
						<li><a href="http://en.pgconf.ru/static/presentations/2015/urbanski.pdf">Urbanski Presentation at pgconf.ru [PDF]</a></li>
						<li><a href="http://www.postgresql.org/docs/current/interactive/explicit-locking.html#LOCKING-DEADLOCKS">Deadlocks in Postgresql</a></li>
					</ul>

				</section>




			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				slideNumber: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});
			Reveal.configure({ slideNumber: 'c / t' });

		</script>

	</body>
</html>
